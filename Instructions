Project Title: Comparative Analysis of ML Algorithms for Slope Stability

Author: Daniel Mateu

Course: Geotechnical Engineering

Goal: Train interpretable and high-performance models to predict slope stability, identifying key geotechnical parameters and testing model robustness across different data splits.

Phase 1: Environment Setup, Data Sourcing & EDA
1.	Project Initialization
    a.	Install libraries: pandas, numpy, scikit-learn, matplotlib, seaborn, jupyter, openpyxl, and xgboost. Install these libraries.
    b.	Create a dedicated /data directory and place the raw Dataset.xlsx file inside.
2.	2. Data Loading and Cleaning
    a.	Initialize a main.ipynb Jupyter Notebook.
    b.	Load the dataset into a dataframe using pd.read_excel().
    c.	Sanitization: Rename all columns to be Python-friendly (lowercase with underscores, e.g., change "Friction Angle (Â°)" to friction_angle_deg).
    d.	Validation: Execute df.info() and df.isnull().sum() to audit data types and identify missing values. Document any data imputation or removal decisions in a Markdown cell.
3.	3. Target Variable Engineering
    a.	Create a binary target column named is_stable
    b.	Map the original status column values to integers: assign 1 for 'Stable' and 0 for 'Failure'.
4.	Exploratory Data Analysis (EDA)
    a.	Class Balance: Generate a seaborn.countplot() to visualize the ratio of Stable vs. Failure cases. Note the severity of any class imbalance
    b.	Feature Correlation: Compute the correlation matrix using df.corr().
    c.	Visualize this using seaborn.heatmap().
    d.	Identify and list the geotechnical features most strongly correlated with the is_stable target.
Phase 2: Multi-Model Training & Robustness Testing
1.	Data Preparation (Primary Split)
    a.	Define the feature matrix (X) and target vector (y).
    b.	Perform the primary 80/20 train-test split using train_test_split.
    c.	Scaling:
        i.	Initialize StandardScaler. Fit the scaler on the training set and transform both the training and testing sets (X_train_scaled, X_test_scaled). This step is mandatory for the SVM model.
2.	Model Training (Primary 80/20 Split)
    a.	Model 1 (Decision Tree): Train a DecisionTreeClassifier on the unscaled data.
    b.	Model 2 (SVM): Train an SVC (Support Vector Classifier) on the scaled data.
    c.	Model 3 (Random Forest): Train a RandomForestClassifier on the unscaled data
    d.	Model 4 (XGBoost): Train an XGBClassifier on the unscaled data.
3.	Primary Evaluation
    a.	Generate a classification_report for all four models.
    b.	Construct a summary table comparing Precision, Recall, and F1-Score.
    c.	Selection: Identify the "Champion Model(s)" based on the highest validation metrics.
4.	Robustness Check (Secondary Split)
    a.	Reshuffle: Create a new, more aggressive 70/30 split of the original dataset.
    b.	Retrain: Train only the Champion Model(s) identified in Step 7 using this new 70% training set.
    c.	Evaluate: Test performance on the new 30% hold-out set.
    d.	Comparison: Create a secondary table comparing the Champion Model's metrics on the 80/20 split versus the 70/30 split to assess stability and overfitting risks.
